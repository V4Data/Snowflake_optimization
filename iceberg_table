# Apache Iceberg Tables in Snowflake

Open table format for data lakes combining Snowflake's query performance with external Parquet storage on S3/Azure/GCS. Supports ACID transactions, schema evolution, time travel, and hidden partitioning without data rewrites.

## Key Features
- ACID Transactions: Atomic commits across multi-table operations
- Schema Evolution: Add/drop/rename columns without rewriting data
- Time Travel: Query historical snapshots via AT(TIMESTAMP => ...)
- Hidden Partitioning: Partition by columns without physical reorganization
- Snapshot Isolation: Concurrent reads/writes without locking

## Table Types

| Type              | Management                  | Read/Write | Interoperability             | Best For                       |
|-------------------|-----------------------------|------------|------------------------------|--------------------------------|
| Snowflake-managed | Snowflake catalog + Volume  | Full R/W   | Limited (Snowflake-only)     | Full features, clustering      |
| External-managed  | AWS Glue/Nessie + Catalog   | Read-only  | Excellent (Spark/Databricks) | Cross-engine lakehouses    |

## Quick Implementation

CREATE ICEBERG TABLE stock_analysis (
symbol STRING,
price FLOAT,
date DATE,
volume BIGINT
)
PARTITIONED BY (date)
CATALOG = 'SNOWFLAKE'
EXTERNAL_VOLUME = 'my_s3_vol'
BASE_LOCATION = 's3://bucket/iceberg/stock_tbl/';
